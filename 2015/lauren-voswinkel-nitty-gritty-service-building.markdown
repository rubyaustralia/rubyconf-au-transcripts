Hi.  So my name is Lauren Voswinkel.  I work for a Living Social, and that is still a company.  So I'm here to talk about service oriented architecture.  What is a service? Many people know the general idea what a service is.  But when I went looking for what it actually should be, according to Wikipedia, they told me it was an unassociated loosely
coupled self-contained unit of functionality.  That's a lot of words in my opinion, for a singly focussed application.  One of the benefits is that many things can be made a synchronous.  You can fire and forget a request and have it run in the background and then have the report generated, or what have you, and sent off via email in the background.  It is parallelisable, meaning it is possible if you are pulling a list of users or various information to make multiple requests at the same time to the same service and have them get back without needing to wait for multiple round trips.  It is, like it said, loosely coupled, meaning that you don't need to worry so much about a change in your service breaking something else that is unrelated to what your change was.  This also leads to faster tests and what I mean by "faster tests" is that the test suite gets broken up into multiple pieces that can be run individually so that when you make a change to one part of your architecture you only need to run the tests for that service.  So it can break up a 30-minute test suite into multiple five-minute test suites.  It is also easier to extend and change because of that lose coupling.  You again don't need to worry about having a change that you make in one service drastically affecting a change in another service.  And finally, it yields an increased velocity because of that quick response time, because you don't have to worry about making changes that break something else.  So I had always heard about this and wondered how, how do you actually build the service? I had tried numerous times to pull out services from existing applications and I felt a lot like this:  A dog with shoes on.  It was a lot of stumbling and just kind of fumbling around trying to figure out what was going on.  So like I said, I work at Living Social.  At Living Social we have so many services.  There are 50-plus services for various things, things like having people login, things like payment information, merchant,
giving merchants information about how their deal is doing and this is all broken up into multiple pieces.  So when I was working there, I work on the finance team and we had decided that we needed a more accurate up-to-date payment information service so that we could update our payment and billing process and also give the merchants more up-to-date information.  So we decided to build a new API, or a new version of the API, which meant we could basically do
what we wanted to do.  So we decided to dog food our own client.  So basically, that meant we were going to pull out our API and have our own client - that is what the payment team used - actually used the same APIs so that we didn't have functionality in our client that didn't exist over the API.  Let's start talking about how did we actually pull out this service and how do we separate the client from the service.  So when building a service you need to determine what the service will actually do.  Services should do one thing well.  They should really just be focussed on, say, providing session information or providing customer information, billing information, things like that and they should really have one particular focus.  Now, within that you can have multiple end points.  That brings us to the second part, which is figuring out and creating what those end points are.  So when thinking about pulling out a session service, you should be thinking, "Okay, there is the ability to create a new session when somebody logs in, there is the ability to check whether that session is currently active, to make sure that the person is still
logged in and there is the ability to destroy a session." So those are basically what your end points are going to be.  So then you build the controllers with those end points in mind, opening
them up to the API to receive various requests.  When you are building those, you need to
determine what options are available in those requests.  What I mean by that is maybe you have filters for the response, say, you've got numerous pieces of information for a customer, like their home address, their social security number, their credit card information.  When you make a

request to this particular service you want to be able to select what pieces you actually show. Another thing that can be used, you can get potentially multiple objects per request.  So when you are asking for users, you can get 10 different users based on various ideas with one request. That makes it so you don't need to worry so much about making parallel requests.  When we at Living Social were creating these various controllers and modelling everything, we ended up going with active model serialisers.  It is a great way to control what you're actually able to get
out of a service by default.  Yes, you can do that by overwriting to JSON in your model but there is a problem in that adding another filter on top of that might actually undo those defaults if it is not coded well.  So it pulls out what is available from that API at all times.  It is really easy to use and understand.  You have a list of attributes and a list of associations.  In this, it segregates all of that information and makes it really simple to figure out what is exposed in your API.  So if you have something like social security information on a user, you can ensure that that never gets exposed through your API.  The other big thing when you are writing the controllers and writing this API basically is you need to write tests.  It is imperative that you write tests because what the tests actually do is they are a contract of what your service actually fulfils.  They tell you, yes,
you are actually able to get XY and Z information.  It basically says, yes, I am providing this information.  So after you do that, you need to create the client models.  How does somebody using your service actually parse the response you have given them?  Don't use the plain responses.  It is a terrible, terrible idea to just take a JSON hash or what have you and just use that.  It gets really hairy, really quickly.  What I ended up doing for rapid prototyping was something really kind of hilariously heinous.  This is a lot of meta programming that basically will take a JSON hash and check to see is the value of this key a hash?  Okay, try to create an object from that.  If the object doesn't exist, it goes out and just assigns that, it creates a method that assigns that value to the return value for that method.  If it does exist it creates model.  If it is an array it - if it is anything else it gets added as a method that returns the plain value.  So it led
to a lot of basically empty classes that, yes, defined this is an object we actually care about.  But then it also gave me the ability to define particular behaviours on the different methods.  Like
this one allowed me to specifically call out and make payment, actual payment, and expected
payment arrays.  Again, this is really great for rapid prototyping, allowing you to build and extend everything very quickly.  But it is absolutely horrible for everything else.  The main reason why it is really terrible is because there is no concreteness to it.  So the next step is basically just testing from the client's side.  Those tests on the client's side are proof your service hasn't changed, it is still providing an expected response.  So the next step is building a
communication layer.  How does your service talk to clients using it? Find a gem, there is a lot of gems out there, HTTP Party, Typhous, Pharaday, all sorts of things rap around the standard
library, which is fine if you want to feel like a hacker and make random jaggy code.  I suggest using Typhous is because it has inbuilt support for concert requests.  It uses curl to make requests
via curl and send the responses back through the gems.  You can, out of the box, cue up 10 different requests and have them run at the same time so you don't have to worry about multiple
round trips around the network.  Wrap the gem when you are using it, don't just use the gem straight up API.  The reason why I really heavily suggest this is because a lot of people probably
experienced one particular gem's pain going from version 2.3 to 3.0.  That would be active record.  When you just use a gem straight, straight from the box, it usually has an API that remains pretty standard, but then when a new version comes out it can drastically change.  When
you wrap it, it provides one place in your code base you actively need to change.  So there is a bonus step that if you take the client models and the communication layer and you add them
together, you get a gem.  Was this a thing in Australia? Okay.  I actually mean a Ruby gem, not gem in the holograms.  So the next step after you create your gem to be kind to all your client
users is to sever dependencies.  You are basically going to replace any direct database calls with a call to the service.  You are going to be creating a gap between the application that currently
exists and the server that it is going to be relying upon.  This is pulling out a service from an existing application.  So this is the step where you start creating that separation between the two
applications.  It is really important to mind that gap.  You need to ensure that gap is being created so when you actually do the extraction there is no pain involved.  One of the biggest problems
that I had when originally doing this service extraction was I had spent multiple hours trying to
figure out why all of my requests were timing out.  Every request I was making to the service would wait the 5, 10, 30 seconds, and it would just end up timing out.  It turns out what I had run into was a web brick wall.  Web brick would basically wait, receive the request and would then have another request cued up behind it that it would, the first request would be waiting on, so
then it would time out, resolve that request, pick up the other one and finish it immediately.  So if you have a server it needs to be able to handle multiple requests, and this step to ensure that you actually get something useful rather than just timing out.  Next part is improving the performance

of your service.  A round trip will always take more time than a database call.  One of the tools that I suggest incredibly heavily, because you really should use tools when you are doing any type of performance profiling, is either stat prof if you are using Ruby 2.1 or higher - pref tools when you first use it is really, really scary.  It is the text view for a request in Rails.  It is really kind of terrifying.  One of the most terrifying things is that top line that says the garbage collection took 67 per cent of the time for the request.  It is kind of terrible.  What ends up, the way to read this is you've got on the far left the number of times that that line's method shows up in the stack as the currently executing piece of code.  And then there is the percentage directly next to it and then the total percentage that has happened with that line and every line before it. So it is a running total.  I completely ignore those for the most part.  I pay attention to the numbers on the fourth column and fifth column, really the fifth column almost exclusively, which is representative of what percentage of time is being spent in that call and any call that it makes so it is all of its descendant calls.  So when you look at something that says it takes up
33.3 per cent of time in that request, that is for when it is the active member in the stack or when it is in the stack at all and that's really useful.  So when digging in it is important to know exactly you are entering into your application.  In this case, using active model serialisers, our requests were almost immediately being picked up by the AZ JSON or to JSON methods.  The second line, the time of the request is exactly the compliment to the 64.3 per cent the garbage collector was taking.  So the entire time of the request that we had direct control over was that 35.7 per cent.  So then digging down further, the next part was looking at the deal serialiser which fast
attributes is basically how long it takes to compile that list of attributes in serialisers and then you look through it and it says growth sales is 5.9 per cent of that.  5.9 per cent is gross sales by itself,
which means roughly 2.1 per cent, is for everything else in fast attributes.  So it helps.  So I then dug in and looked at gross sales and eventually found coupon calculator which the coupons
method took 21.5 per cent of time.  So that is 10 per cent less than the total time that it took to
run the request.  So this is basically the method that I needed to focus all of my time on.  Because that was taking two-thirds of entire time to process everything.  It turns out it was a big part of
processing all the objects that the garbage collector would take time as well.  So that is a rough
review of peripherals and how to drill down into things.  The last thing you need to do is to actually transfer the client or service and pull it out from the application that you were working with.  So you need to extract the tables and/or the database that is involved in that, pull it down into a separate instance so that it is not working on the same instance as everything else, because that leads to terrible things.  A lot of Living Social's code shares a database and it gets difficult and confusing to deal with because another application will make a change to the data you are looking at and you have to wait for that application to make the change and it is confusing.  So
try to extract the tables and database for any servers you build.  Then you need to make the actual extraction from the code base perspective, just pulling out all of the controllers you build, pulling out the models you build, pulling out the client you built, make that separation as complete as possible.  Build it into a gem, build it into another Git repository.  This also includes pulling out all the tests and everything for that particular service. That's it.  Thanks.
